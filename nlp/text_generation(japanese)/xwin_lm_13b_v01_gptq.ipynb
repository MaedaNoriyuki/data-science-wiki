{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WSS3uOWJ1Re"
      },
      "source": [
        "# Xwin-LM-13B-V0.1-GPTQ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LvAMjrX0xtN"
      },
      "source": [
        "\u30aa\u30fc\u30d7\u30f3\u30bd\u30fc\u30b9\u306eLLM\u3068\u3057\u3066\u306f\u3058\u3081\u3066GPT-4\u3092\u8d85\u3048\u308b\u7cbe\u5ea6\u3092\u51fa\u3057\u305f(AlpacaEval\u306e\u8a55\u4fa1\u57fa\u6e96\u306b\u304a\u3044\u3066)\u3068\u3057\u3066\u975e\u5e38\u306b\u6ce8\u76ee\u3092\u96c6\u3081\u3066\u3044\u308b\u30e2\u30c7\u30eb\u3067\u3059\uff0eLlama2\u3092\u30d9\u30fc\u30b9\u306b\u6559\u5e2b\u3042\u308a\u30d5\u30a1\u30a4\u30f3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3001\u5831\u916c\u30e2\u30c7\u30eb\u3001\u30ea\u30b8\u30a7\u30af\u30c8\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3001\u5f37\u5316\u5b66\u7fd2\u306a\u3069\u3092\u4f7f\u3044\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8abf\u6574\u3057\u305f\u305d\u3046\u3067\u3059\uff0e\u3053\u3053\u3067\u306fXwin-LM\u306e13B\u306e\u30e2\u30c7\u30eb\u3092\u91cf\u5b50\u5316\u3057\u305f\u30e2\u30c7\u30eb\u3092\u3092\u6271\u3044\u307e\u3059\uff0e  \n",
        "* https://github.com/Xwin-LM/Xwin-LM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fuyu-quant/data-science-wiki/blob/develop/nlp/text_generation(japanese)/xwin_lm_13b_v01_gptq.ipynb\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9O4Lqh-ZKMi5"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VtgVI0qKXXm"
      },
      "source": [
        "### Xwin-LM-13B-V0.1-GPTQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "90144f15a7fe43b9974dcb5aaf9bae7d",
            "f5bb5af175ff42788034efca530c38ec",
            "df1a549a9cb844de87c413ae2c6850d1",
            "96f65c32bd0343a18fab47c5fe57a5cb",
            "348b5eb459224524bca76fc63b7fb9f1",
            "7316c9d491ee4efe815da85543d9944b",
            "bf4f8df9591640379bad41c6f20acfeb",
            "ae120e88593a4e5bbc21a3345b2b2559",
            "eeb5e884b7a04746bfa72fab60a6b0ee",
            "60aec6e34b53461b813340cb30061e59",
            "e9fc9bb921ef452482c5bea2767758df",
            "bd16cc02878b4616989c3fece98155f6",
            "b227e8b53c9747aeb094b9f41d266d51",
            "5867b934541a4cfc95d2fb9efb769b1d",
            "72f56669a02241bf98bf45ca57eeb13a",
            "5477f28d2e5a4c3a87b365c8b85147e4",
            "dc84b4e33d0649a1952f3979fdb83d65",
            "a7d254e6cce04ae182428ec35ce7ebbf",
            "ec6519861f2241db9c5bab501714d5bf",
            "88d4771376884c708662c67cf39c0a08",
            "fb7024a5b62246e9a280045a552ef357",
            "8047c58b5db74cfd8964bd9a73ec6d52",
            "615e34d86a7e48e19413c44a86c6f798",
            "0ee3065f326149abac63ad6fc61a8a3a",
            "89ac5d1f703d44c1bb7c341a73a64cd8",
            "38d5789c864148e0af9c4c152859a278",
            "f08bf17839c64c50aec1f56f8332567f",
            "e9d6199f7e1e463492d41bf96618e53a",
            "f980af1a7ec34c38bfceef18f59b0110",
            "c27189f69ca949b1b0b2f4304e599eee",
            "0116d691060748a8a81c564df7cf896c",
            "cfe09913c49642acbe454ce18a37d505",
            "56de4b11fe47407db35be8c6654c3005",
            "ac5b269ebfa447eca5c914d26551b283",
            "3b5fe9b89fb84158aa9f236393179b00",
            "bf5c17c486114274b38d55d0fb1c0136",
            "ce2a84c924f24c59ae2fb4084c1ff835",
            "51fa777e5a8c4c3c87c12c26c6b70dcc",
            "a8d45d0592704ad298fdf223e9240c0d",
            "5964d759345d4c628815441b90f1955a",
            "129cc66610b746588206c56ec1554545",
            "43dc2e6bf39f4c9ea2e8bd1e0c7e168d",
            "d7c477ba871f454ba48ded59532a8539",
            "12c8b087282442f9bde428ff67a23eaf",
            "6a6145905c0b4a5288dae171efd758a7",
            "0a86d5fd61864691a09f2290ab49293e",
            "6e22964266a2419ca9b5665bdc7dd6e1",
            "be7dc6715c8b4494ae57652219c9b1eb",
            "81d274f07eb24bd2b3f3e2be1b457625",
            "89e2135f659f417e92c34a9908493b14",
            "8c460085d6a6407c9f4ab5ced5d3b342",
            "5df88155444444d499b3d5265007962d",
            "7293503476f64855be69f438e1456644",
            "899988e6a6d54abc89eec9f0a207153d",
            "3ae9d6bbece74ab5bc413e508419a798",
            "f852e0d3d570437ab9aa78d65089e2c6",
            "b3968efa6b924696b5473bb06a100881",
            "a55e183e13d04bcebc2a937cda661100",
            "019b3151c8774bd7aaffcf97c8c19b0a",
            "447fe1e458854404a4192c0f37ebc75a",
            "37ee7a143bf946b8b36b023843a546e2",
            "2c4b7337518542e3895c7e57737d47f4",
            "ff401c69d93f476385e119e2781ff3aa",
            "f38e4c4425b74dee93efbcd7caca3254",
            "c5012a4294d848e5a3326d4e07f678ec",
            "5f2797175dec4b64a1c10b7aaa85166d",
            "7bbad8c1125d499daf263c25b80d40d1",
            "27b352718f9b46b2883a904f000ce91b",
            "1bf53a7631d14657ac5c56b9816a73b7",
            "0e7203033226474f9bb7d1f9c01801d0",
            "bedc64518caa4360ad70b060f72e7ec9",
            "744b851b8dbf46b6be272f4568fe27d7",
            "08728ff9ca784d5a9d865c434c9059f3",
            "939ab15cbe98436fbb47c7a849b0d29f",
            "dc9202b8502940b18a02ff432f2a1450",
            "817608ea93514ff2bf785db21fa3bfd8",
            "b33aa51fed0142fca1b6c9765d28ca17"
          ]
        },
        "id": "MaSKC3MXJw-k",
        "outputId": "e996676f-601e-4edd-87a8-c0802a0ab37c"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"TheBloke/Xwin-LM-13B-V0.1-GPTQ\", \n",
        "    use_fast=True\n",
        "    )\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"TheBloke/Xwin-LM-13B-V0.1-GPTQ\", \n",
        "    device_map=\"auto\", \n",
        "    trust_remote_code=False, \n",
        "    revision=\"main\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQwA4RDTSuJI"
      },
      "source": [
        "### \u65e5\u672c\u8a9e\u306e\u51fa\u529b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfHKmLJZMiB8"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"### Instruction:\n",
        "\u91cf\u5b50\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u306b\u3064\u3044\u3066\u6559\u3048\u3066\u304f\u3060\u3055\u3044\uff0e\n",
        "\n",
        "### Response:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a20M3CwKWPL",
        "outputId": "b7f8fd8e-1880-412c-ae9d-b869ce40c8bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u91cf\u5b50\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u306f\u3001\u91cf\u5b50\u7269\u7406\u73fe\u8c61\u3092\u5229\u7528\u3057\u305f\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u3067\u3059\u3002\u3053\u308c\u306f\u3001\u901a\u5e38\u306e\u30af\u30e9\u30b7\u30ab\u30eb\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u3068\u306f\u7570\u306a\u308a\u3001\u60c5\u5831\u51e6\u7406\u306b\u91cf\u5b50\u72b6\u614b\u3092\u4f7f\u7528\u3059\u308b\u70b9\u304c\u7279\u5fb4\u3067\u3059\u3002\u91cf\u5b50\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u306f\u3001\u91cf\u5b50\u30d3\u30c3\u30c8\uff08\u30af\u30a9\u30fc\u30c8\uff09\u3092\u4f7f\u7528\u3057\u3066\u60c5\u5831\u3092\u6271\u3044\u3001\u3053\u308c\u3089\u306e\u30af\u30a9\u30fc\u30c8\u306f\u3001\u78ba\u7387\u7684\u306b0\u30681\u306e\u72b6\u614b\u3092\u3068\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n",
            "\n",
            "\u91cf\u5b50\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u306e\u4e3b\u306a\u7279\u5fb4\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3067\u3059\u3002\n",
            "\n",
            "1. \u30b9\u30fc\u30d1\u30fc\u30dd\u30b8\u30b7\u30e7\u30f3: \u91cf\u5b50\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u306f\u3001\u30af\u30e9\u30b7\u30ab\u30eb\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u306b\u306f\u306a\u3044\u30b9\u30fc\u30d1\u30fc\u30dd\u30b8\u30b7\u30e7\u30f3\u3092\u6301\u3061\u307e\u3059\u3002\u3053\u308c\u306f\u3001\u540c\u6642\u306b\u8907\u6570\u306e\u72b6\u614b\u3092\u6301\u3064\u3053\u3068\u304c\u3067\u304d\u308b\u3053\u3068\u3067\u3059\u3002\u3053\u308c\u306b\u3088\u308a\u3001\u91cf\u5b50\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u306f\u3001\u8907\u96d1\u306a\u554f\u984c\u3092\u89e3\u304f\u306e\u306b\u5fc5\u8981\u306a\u9ad8\u901f\u306a\u8a08\u7b97\u3092\u884c\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n",
            "2. \u30d1\u30e9\u30ec\u30ea\u30ba\u30e0: \u91cf\u5b50\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u306f\u3001\u30af\u30e9\u30b7\u30ab\u30eb\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u306b\u6bd4\u3079\u3066\u30d1\u30e9\u30ec\u30ea\u30ba\u30e0\u304c\u9ad8\u3044\u305f\u3081\u3001\u4e26\u5217\u51e6\u7406\u304c\u52b9\u7387\u7684\u306b\u884c\u308f\u308c\u307e\u3059\u3002\u3053\u308c\u306b\u3088\u308a\u3001\u9ad8\u901f\u306a\u8a08\u7b97\u304c\u53ef\u80fd\u3067\u3042\u308a\u3001\u8907\u96d1\u306a\u554f\u984c\u3092\u89e3\u304f\u306e\u306b\u9069\u3057\u3066\u3044\u307e\u3059\u3002\n",
            "3. \u6697\u53f7\u5316\u3068\u691c\u8a3c: \u91cf\u5b50\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u306f\u3001\u6697\u53f7\u5316\u3068\u691c\u8a3c\u306b\u9069\u3057\u3066\u3044\u307e\u3059\u3002\u3053\u308c\u306f\u3001\u91cf\u5b50\u30d3\u30c3\u30c8\u306e\u78ba\u7387\u7684\u6027\u8cea\u3092\u5229\u7528\u3057\u3066\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    token_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
        "    output_ids = model.generate(\n",
        "        token_ids.to(model.device),\n",
        "        temperature=0.01,\n",
        "        do_sample=True,\n",
        "        top_p=0.95,\n",
        "        top_k=40,\n",
        "        max_new_tokens=512,\n",
        "    )\n",
        "\n",
        "output = tokenizer.decode(output_ids.tolist()[0][token_ids.size(1) :], skip_special_tokens=True)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa4NZhg6SyD_"
      },
      "source": [
        "### \u30b3\u30fc\u30c9\u751f\u6210"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbKoRhBGlTub"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"### Instruction:\n",
        "LightGBM\u3092\u5b66\u7fd2\u3059\u308b\u305f\u3081\u306ePython\u306e\u30b3\u30fc\u30c9\u3092\u751f\u6210\u3057\u3066\u304f\u3060\u3055\u3044\uff0e\n",
        "\n",
        "### Response:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWdgH51em6UI",
        "outputId": "5d143a28-9421-4e5d-dc08-7fff63de5881"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```python\n",
            "import numpy as np\n",
            "import pandas as pd\n",
            "from lightgbm import LGBMClassifier\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
            "\n",
            "# \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u8aad\u307f\u8fbc\u307f\n",
            "data = pd.read_csv(\"./data.csv\")\n",
            "X = data.drop(\"target\", axis=1)\n",
            "y = data[\"target\"]\n",
            "\n",
            "# \u30c7\u30fc\u30bf\u306e\u5206\u5272\n",
            "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
            "\n",
            "# LightGBM\u306e\u5b66\u7fd2\n",
            "gbm = LGBMClassifier()\n",
            "gbm.fit(X_train, y_train)\n",
            "\n",
            "# \u4e88\u6e2c\n",
            "y_pred = gbm.predict(X_test)\n",
            "\n",
            "# \u7d50\u679c\u306e\u8868\u793a\n",
            "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
            "print(\"Classification Report:\")\n",
            "print(classification_report(y_test, y_pred))\n",
            "print(\"Confusion Matrix:\")\n",
            "print(confusion_matrix(y_test, y_pred))\n",
            "```\n",
            "\u3053\u306e\u30b3\u30fc\u30c9\u306f\u3001\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u8aad\u307f\u8fbc\u307f\u3001LightGBM\u30e2\u30c7\u30eb\u3092\u5b66\u7fd2\u3057\u3001\u4e88\u6e2c\u7d50\u679c\u3092\u5f97\u308b\u305f\u3081\u306e\u57fa\u672c\u7684\u306a\u624b\u9806\u3092\u5b9f\u884c\u3057\u3066\u3044\u307e\u3059\u3002\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u69cb\u9020\u3084\u30bf\u30b9\u30af\u306b\u5fdc\u3058\u3066\u3001\u5fc5\u8981\u306b\u5fdc\u3058\u3066\u30d1\u30e9\u30e1\u30fc\u30bf\u3084\u624b\u9806\u3092\u8abf\u6574\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    token_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
        "    output_ids = model.generate(\n",
        "        token_ids.to(model.device),\n",
        "        temperature=0.01,\n",
        "        do_sample=True,\n",
        "        top_p=0.95,\n",
        "        top_k=40,\n",
        "        max_new_tokens=512,\n",
        "    )\n",
        "\n",
        "output = tokenizer.decode(output_ids.tolist()[0][token_ids.size(1) :], skip_special_tokens=True)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbk5eLWiS0Lc"
      },
      "source": [
        "### \u82f1\u8a9e\u306e\u51fa\u529b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWC24uHum63g"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"### Instruction:\n",
        "Please tell me about quantum computers.\n",
        "\n",
        "### Response:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFWRC7hFnMtr",
        "outputId": "fff1b0db-1649-4a86-ad75-04c8d39303dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quantum computers are a type of computer that uses the principles of quantum mechanics to perform computations. They differ from classical computers in several key ways:\n",
            "\n",
            "1. Quantum bits (qubits): Unlike classical computers that use bits (0 or 1), quantum computers use quantum bits or qubits. A qubit can exist in a superposition of states (both 0 and 1 at the same time) until it is measured, at which point it collapses to either 0 or 1.\n",
            "2. Entanglement: Quantum computers can exploit entanglement, a property where two or more qubits become interconnected, so that the state of one qubit cannot be described independently of the state of the other, even when they are separated by large distances. This property allows quantum computers to perform certain types of computations much more efficiently than classical computers.\n",
            "3. Parallelism: Quantum computers can perform multiple computations simultaneously due to the principles of quantum mechanics. This is known as quantum parallelism and allows quantum computers to solve certain types of problems much faster than classical computers.\n",
            "4. Quantum gates: Quantum computers use quantum gates, which are the basic building blocks of quantum circuits. Quantum gates operate on qubits and can perform operations like adding, multiplying, or rotating the state of a qubit.\n",
            "5. Quantum algorithms: Quantum computers use quantum algorithms, which are designed to take advantage of the unique properties of quantum computers. Some examples of quantum algorithms include Shor's algorithm for factoring large numbers and Grover's algorithm for searching unsorted databases.\n",
            "6. Error correction and noise: Quantum computers are sensitive to noise and errors, so error correction and fault-tolerant quantum computing are essential for building practical quantum computers. This involves using quantum error correction codes and fault-tolerant quantum gates to protect the quantum state from decoherence and errors.\n",
            "\n",
            "Quantum computers have the potential to solve certain types of problems much more efficiently than classical computers, particularly in areas like cryptography, optimization, and simulation of quantum systems. However, building practical quantum computers remains a significant challenge due to the need for advanced technologies and error-correction techniques.\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    token_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
        "    output_ids = model.generate(\n",
        "        token_ids.to(model.device),\n",
        "        temperature=0.01,\n",
        "        do_sample=True,\n",
        "        top_p=0.95,\n",
        "        top_k=40,\n",
        "        max_new_tokens=512,\n",
        "    )\n",
        "\n",
        "output = tokenizer.decode(output_ids.tolist()[0][token_ids.size(1) :], skip_special_tokens=True)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.18 ('.venv': poetry)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.18"
    },
    "vscode": {
      "interpreter": {
        "hash": "17a011378fed683b21aba93e5dd7c0cb7beefc09c5af72c6425b40c713e260dc"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}