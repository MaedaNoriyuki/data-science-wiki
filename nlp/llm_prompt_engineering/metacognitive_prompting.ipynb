{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metacognitive Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLMに人間の認知プロセスを模倣させることで精度を改善した手法．\n",
    "- 論文:https://arxiv.org/abs/2308.05342"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/fuyu-quant/data-science-wiki/blob/develop/nlp/llm_prompt_engineering/metacognitive_promting.ipynb\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanakatouma/vscode/data-science-wiki/.venv/lib/python3.9/site-packages/langchain/llms/openai.py:202: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/Users/tanakatouma/vscode/data-science-wiki/.venv/lib/python3.9/site-packages/langchain/llms/openai.py:790: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm_model = OpenAI(model_name= 'gpt-3.5-turbo', temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通常のプロンプト(Few-shot prompting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "質問1: 「世界で最も美しいビーチは何ですか？」と質問2:「最も美しいビーチは何ですか？」、\n",
    "これら2つの質問がお互いの言い換えであるかどうかを判断してください。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "これらの2つの質問はお互いの言い換えではありません。質問1は「世界で最も美しいビーチは何ですか？」という具体的な範囲を指定しており、質問2は単に「最も美しいビーチは何ですか？」と一般的な美しいビーチを尋ねています。質問1は特定の範囲を指定しているため、回答もより具体的になる可能性があります。\n"
     ]
    }
   ],
   "source": [
    "output = llm_model(prompt)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metacognitive Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = \"\"\"\n",
    "質問1: 「世界で最も美しいビーチは何ですか？」と質問2:「最も美しいビーチは何ですか？」、\n",
    "これら2つの質問がお互いの言い換えであるかどうかを判断してください。\n",
    "Q:両方の質問に対するあなたの理解を明確にしてください。\n",
    "A:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "質問1: 「世界で最も美しいビーチは何ですか？」\n",
      "この質問は、世界中のビーチの中で最も美しいビーチを尋ねています。\n",
      "\n",
      "質問2: 「最も美しいビーチは何ですか？」\n",
      "この質問も、最も美しいビーチを尋ねていますが、特定の地域や範囲については言及していません。\n",
      "\n",
      "これらの質問は意味的には非常に似ていますが、質問1は「世界で」という限定語を使用しており、特定の地域や範囲について尋ねていることを示しています。一方、質問2は特定の地域や範囲については言及せず、単に最も美しいビーチを尋ねています。したがって、これらの質問はお互いの言い換えではありません。\n"
     ]
    }
   ],
   "source": [
    "output1 = llm_model(prompt1)\n",
    "print(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = \"\"\"\n",
    "質問1: 「世界で最も美しいビーチは何ですか？」と質問2:「最も美しいビーチは何ですか？」、\n",
    "これら2つの質問がお互いの言い換えであるかどうかを判断してください。\n",
    "Q:両方の質問に対するあなたの理解を明確にしてください。\n",
    "A:{output1_}\n",
    "Q:主題、文脈、意味内容に基づく類似性の予備的識別を行う。\n",
    "A:\n",
    "\"\"\".format(\n",
    "    output1_=output1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "主題: 両方の質問は「美しいビーチ」に関連しています。\n",
      "文脈: 両方の質問はビーチに関する情報を尋ねています。\n",
      "意味内容: 両方の質問は最も美しいビーチについて尋ねています。\n",
      "\n",
      "以上の要素から、両方の質問は主題、文脈、意味内容の面で類似していると言えます。ただし、質問1は特定の地域や範囲について尋ねている点で質問2と異なります。\n"
     ]
    }
   ],
   "source": [
    "output2 = llm_model(prompt2)\n",
    "print(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3 = \"\"\"\n",
    "質問1: 「世界で最も美しいビーチは何ですか？」と質問2:「最も美しいビーチは何ですか？」、\n",
    "これら2つの質問がお互いの言い換えであるかどうかを判断してください。\n",
    "Q:両方の質問に対するあなたの理解を明確にしてください。\n",
    "A:{output1_}\n",
    "Q:主題、文脈、意味内容に基づく類似性の予備的識別を行う。\n",
    "A:{output2_}\n",
    "Q:予備的な分析を批判的に評価する。質問がパラフレーズであるという最初の評価に確信が持てない場合は、再評価を試みる。\n",
    "A:\n",
    "\"\"\".format(\n",
    "    output1_=output1,\n",
    "    output2_=output2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "予備的な分析は適切に行われており、質問1と質問2の類似性と相違点を明確に示しています。質問1は特定の地域や範囲について尋ねている一方、質問2は特定の地域や範囲について言及していません。この違いにより、質問1と質問2はお互いの言い換えではないという結論が導かれます。\n",
      "\n",
      "再評価を試みる必要はありません。\n"
     ]
    }
   ],
   "source": [
    "output3 = llm_model(prompt3)\n",
    "print(output3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt4 = \"\"\"\n",
    "質問1: 「世界で最も美しいビーチは何ですか？」と質問2:「最も美しいビーチは何ですか？」、\n",
    "これら2つの質問がお互いの言い換えであるかどうかを判断してください。\n",
    "Q:両方の質問に対するあなたの理解を明確にしてください。\n",
    "A:{output1_}\n",
    "Q:主題、文脈、意味内容に基づく類似性の予備的識別を行う。\n",
    "A:{output2_}\n",
    "Q:予備的な分析を批判的に評価する。質問がパラフレーズであるという最初の評価に確信が持てない場合は、再評価を試みる。\n",
    "A:{output3_}\n",
    "Q:質問がパラフレーズであるかどうかの最終的な判断を確認し、判断の根拠を示します。\n",
    "A:\n",
    "\"\"\".format(\n",
    "    output1_=output1,\n",
    "    output2_=output2,\n",
    "    output3_=output3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "質問1と質問2は、意味的には非常に似ていますが、質問1は「世界で」という限定語を使用しており、特定の地域や範囲について尋ねていることを示しています。一方、質問2は特定の地域や範囲については言及せず、単に最も美しいビーチを尋ねています。したがって、これらの質問はお互いの言い換えではありません。この判断は、質問の主題、文脈、意味内容の面での類似性と相違点に基づいています。\n"
     ]
    }
   ],
   "source": [
    "output4 = llm_model(prompt4)\n",
    "print(output4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt5 = \"\"\"\n",
    "質問1: 「世界で最も美しいビーチは何ですか？」と質問2:「最も美しいビーチは何ですか？」、\n",
    "これら2つの質問がお互いの言い換えであるかどうかを判断してください。\n",
    "Q:両方の質問に対するあなたの理解を明確にしてください。\n",
    "A:{output1_}\n",
    "Q:主題、文脈、意味内容に基づく類似性の予備的識別を行う。\n",
    "A:{output2_}\n",
    "Q:予備的な分析を批判的に評価する。質問がパラフレーズであるという最初の評価に確信が持てない場合は、再評価を試みる。\n",
    "A:{output3_}\n",
    "Q:質問がパラフレーズであるかどうかの最終的な判断を確認し、判断の根拠を示します。\n",
    "A:{output4_}\n",
    "\"\"\".format(\n",
    "    output1_=output1,\n",
    "    output2_=output2,\n",
    "    output3_=output3,\n",
    "    output4_=output4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "質問1と質問2はお互いの言い換えではないと判断されます。質問1は特定の地域や範囲について尋ねている一方、質問2は特定の地域や範囲について言及していません。この判断は、質問の主題、文脈、意味内容の面での類似性と相違点に基づいています。\n"
     ]
    }
   ],
   "source": [
    "output5 = llm_model(prompt5)\n",
    "print(output5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt6 = \"\"\"\n",
    "質問1: 「世界で最も美しいビーチは何ですか？」と質問2:「最も美しいビーチは何ですか？」、\n",
    "これら2つの質問がお互いの言い換えであるかどうかを判断してください。\n",
    "Q:両方の質問に対するあなたの理解を明確にしてください。\n",
    "A:{output1_}\n",
    "Q:主題、文脈、意味内容に基づく類似性の予備的識別を行う。\n",
    "A:{output2_}\n",
    "Q:予備的な分析を批判的に評価する。質問がパラフレーズであるという最初の評価に確信が持てない場合は、再評価を試みる。\n",
    "A:{output3_}\n",
    "Q:質問がパラフレーズであるかどうかの最終的な判断を確認し、判断の根拠を示します。\n",
    "A:{output4_}\n",
    "Q:自分の分析に対する確信度（0～100％）を評価し、その確信度の説明をする。\n",
    "A:\n",
    "\"\"\".format(\n",
    "    output1_=output1,\n",
    "    output2_=output2,\n",
    "    output3_=output3,\n",
    "    output4_=output4,\n",
    "    output5_=output5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自分の分析に対する確信度は90％です。質問1と質問2の類似性と相違点を明確に示し、それぞれの質問が異なる範囲を尋ねていることを示しています。ただし、確信度が100％ではないのは、他の文脈や意味の解釈が考えられるためです。しかし、現時点では質問1と質問2はお互いの言い換えではないという結論に自信を持っています。\n"
     ]
    }
   ],
   "source": [
    "output6 = llm_model(prompt6)\n",
    "print(output6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17a011378fed683b21aba93e5dd7c0cb7beefc09c5af72c6425b40c713e260dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
