{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-drJ5owo2_Wf"
      },
      "source": [
        "# phi-1.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eMwmvBh5ZGU"
      },
      "source": [
        "13\u5104\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u307f\u3067100\u4ee5\u4e0b\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u30e2\u30c7\u30eb\u306b\u5e38\u8b58\uff0c\u8a00\u8a9e\u7406\u89e3\uff0c\u8ad6\u7406\u7684\u63a8\u8ad6\u3092\u30c6\u30b9\u30c8\u3059\u308b\uff13\u3064\u306e\u30d9\u30f3\u30c1\u30de\u30fc\u30af\u3067\u6700\u5148\u7aef\u306e\u6027\u80fd\u3092\u51fa\u3057\u307e\u3057\u305f\uff0e\u73fe\u72b6\u3067\u306f\u7814\u7a76\u76ee\u7684\u3067\u306e\u307f\u5229\u7528\u3067\u304d\uff0c\u65e5\u672c\u306f\u51fa\u529b\u3067\u304d\u307e\u305b\u3093\uff0e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89V83x2J5Z60"
      },
      "source": [
        "* https://huggingface.co/microsoft/phi-1_5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fuyu-quant/data-science-wiki/blob/develop/nlp/text_generation(japanese)/phi_1_5.ipynb\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mmIHP_4x5z64"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dspMzuOq5XJ9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491,
          "referenced_widgets": [
            "c0338d672c8941f288ddc27382d01be9",
            "00cb21c605f942e79aab52f4e5d18fd0",
            "be82b1bfd0f9425488183b1930cc2b70",
            "1f22a194e426433a907642679908214f",
            "8b50543b4a384f53b941a8f373e34728",
            "015ceacd7d1c4b2dad67888f740b2fa9",
            "509f67ac28ec43e6a70eb50e4e766399",
            "b793efc65eb3485f8c921cbadbedd5fd",
            "fa1fec4506a24cce8393d65230454174",
            "b89a89da993c412788b2c417a642847a",
            "e1a9d3d9a33c47d79b81177ec1f45810",
            "26879b0ca5904c16a62d4dd88adcd782",
            "f0f925d570914324af112a2e5b708fbb",
            "abba4ac36528450f8befb92fc7108ee7",
            "67273a7965be4c1bb0949166a46e4bff",
            "e80f6ff88cd14717ad60538e429a474f",
            "e95315f9e2fc49bf9d958dc01eb7f6d7",
            "f872a9ddc80e4c1a93c5bcfb432fc775",
            "9b2522ed684a4a509d49ae0984f189c2",
            "cc80edca13de4aab89545dace7397099",
            "716088d4787a4beba4c3dc8c4543a5b4",
            "802f1729b6bd419a95222e5c5fd2a7a5",
            "d538148380b94d6aa4be5a70918b513f",
            "b1db37671f1a4d95b0739c8b7d5dd5c5",
            "a8500949ace2441db1d6f7e8b5178a6e",
            "d4daaa83a699406e8a1c6092cbe02c62",
            "f5404398f63a43049176254f72047525",
            "bc7fe84b5f2d436a94b89a5660ccc799",
            "0b24d7d665e24c618c10ca0258f071cf",
            "1db9e5915db14156909b8d727a75d5fc",
            "bff9ff86ff4b46cfa0928e5863c3fef6",
            "a8d887ce0e784859a06770fcce8dd109",
            "0757c1e66e2d4d1582a04a706d250d3b",
            "d037602660c04c53b28ca7b82734e025",
            "2b8ba84509934229b5d4a1f5b8885bee",
            "be815cbc9cfb4cbc93db7b09aaf86d93",
            "85ee20c7d1c446858ae289dec17f4142",
            "54b2acf75ed04b1d846fa9fe551c4a43",
            "dd207945b638410083f070f285509b3e",
            "2987f3c2d09646d0b5a29fa1ba124d27",
            "c8aa8e676af149b0ab04d2d3eeeef97b",
            "ed32ec07a5bd4f7893d636d05c9fe75b",
            "18b352f101024c1f8f87f3bcec6e21b8",
            "7cb63485c1ee4a22adf1fb0b336e8d0d",
            "7d916c8d6743431c9c7441d155694745",
            "55a9ac56e543455bac5e4c7d3a9a80b9",
            "79cc52edb4cc4012a38baac4179085fd",
            "5254cbe5f5be4c0eb6f27388d47212ab",
            "d9527806d723496a938e8d4926f1591a",
            "b4816330719a4835af30125997301f55",
            "27919d1934d84329a88734c5d3d19ce1",
            "958184ca6e764376bf859ced1d47d82b",
            "69904af506524923a5a37400c1cdaac3",
            "f74bc3f4fccb4b669bf8eedcb76c2fff",
            "acc136f757b8437bbe858080bfbbfe9e",
            "7a31218639644bf79484be1355f86b12",
            "471663c746c64f668eb7d924632c532b",
            "de049c54883b4ca2a6546c76e20713d5",
            "1b6fe07875b04d73a8afd7bdfe5ae2a6",
            "0612695c1ec04a47a5d235112825da30",
            "dd7353940f29422a9ea06657889b8719",
            "fe3d36c47f9c4dba91392b8e9e765745",
            "7550c2c3117145dca6ac735066014fa7",
            "5ab24183d6664a9a95822682e936e43b",
            "09b65ebba1284a0ca41792ab82c79563",
            "077c2907a83b42a883e14a3611aab511",
            "0c318070509546408360157114cbb0e6",
            "2cecba86d45b4659ba9e419ec45a78b5",
            "13b62b73a36943bdb138b0d8dadfa3b4",
            "ac6e027f0d9c42c4b0137acc4c3ccb43",
            "d7886a09bb2a4875adef7f4dcc502ada",
            "b5f860f6fa624d0887798bdc79607833",
            "d4d96c0a424e413285b7e783f6259eca",
            "b91db9428fe54b1b9ec6ab0c3b705baa",
            "dcfef79ea8ff42a2a1fe8d86b9021566",
            "b5496f05d759497d987b49a0f5b41d8d",
            "441ab7179c9b475e98b525734283956e",
            "814df79e0f6840c5acd2bca8dd1483e7",
            "a5f57fb70a114a148010fbbc8bde96f0",
            "2d8235fef71b4234af2b90d810afca4d",
            "439ee02d49da4cb6ad782b425ac8c74a",
            "a21ecae698374dd4bd226746cebcc32d",
            "c4519a22b5fe4dc88b0525a0557bdf81",
            "34853ffd70554b6ca6feedc4ddbd802f",
            "1fddc049b5ca4133a78f86f5e5e20789",
            "a6722ab21f154479a4751f1e34450f15",
            "db7d3f10491944e3b950f6bda58d1ae1",
            "399ecdf49e2744e1b6a2830e108ab25e",
            "2c6eeb3b34554d67903492e63015809c",
            "2db9413416c84194826edf661841eaf3",
            "20904d83a16d4ab79fd9228dd755f06b",
            "43eddddd730d42608a11f9f7666ee318",
            "6e5b29dab0d640c4b83ffdb91685bb05",
            "68f4df5b4d1241e29c16c5c1fda74cee",
            "d23f4fed000b467cb66249ddf80eed69",
            "b8b7fa393378412c88afd1b4cf2b6887",
            "d882d2298af344318945bfacddc26972",
            "ed2ee4aec97140369c1497920c932948",
            "e56aaf0a3d9c4451ba8e75192e11f288",
            "1295dbd1b0af4510ada8310e7a4b4e3f",
            "06cbb45d8d5d4b4d91d07ddbfcd15e85",
            "5ed52717565443f0acc9044c05e3c8c1",
            "489bc901ba144e3e948435d3938255f5",
            "edd89f2e79024429af64955ca405697c",
            "b49f108e4ff54c9e93e9cdf096484ead",
            "74cf6d9fd26f46aeaa151afc92600cab",
            "cc65ec54a27f4ef18499f3c48a26d8e3",
            "e3f632952f7749f2aeba864908030dc7",
            "5b4a538da261409d86aa3030a5809609",
            "7c3c2eee613f406d85ed10511fb8d5c9",
            "3d10def3096b4637965147405f70afc3",
            "502d039d867944c087d21ba2640cbe99",
            "b30e61cf57254214b6ebe24c4faaa32d",
            "93e65e5010864e79b98575e2c53e1df9",
            "b844ae14880d4d7fa182f6e66ac36c0a",
            "66befdb8bc3c448eac64545f532bf373",
            "09fa7079294d4dde991610510bec29d8",
            "f13a673c5dcb465f82d56c67d14acc3d",
            "3937d9eb920947848e19380070f6f6dd",
            "1b887758d4fd407e8269e77e482abc16",
            "c2186be4989c4170a73ee772e4e7d1c1"
          ]
        },
        "id": "_XMa0K9R28Cu",
        "outputId": "d5ef920e-813e-4d13-9a9f-58eff972bb98"
      },
      "outputs": [],
      "source": [
        "torch.set_default_device(\"cuda\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-1_5\", trust_remote_code=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-1_5\", trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tb_Nms6h8hWO"
      },
      "outputs": [],
      "source": [
        "prompt = '''```python\n",
        "def print_prime(n):\n",
        "   \"\"\"\n",
        "   Print all primes between 1 and n\n",
        "   \"\"\"'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTw_Vn4a8cz2",
        "outputId": "04298138-288a-48d4-c067-bdb3d8325b97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```python\n",
            "def print_prime(n):\n",
            "   \"\"\"\n",
            "   Print all primes between 1 and n\n",
            "   \"\"\"\n",
            "   primes = []\n",
            "   for num in range(2, n+1):\n",
            "       is_prime = True\n",
            "       for i in range(2, int(num**0.5)+1):\n",
            "           if num % i == 0:\n",
            "               is_prime = False\n",
            "               break\n",
            "       if is_prime:\n",
            "           primes.append(num)\n",
            "   print(primes)\n",
            "\n",
            "print_prime(20)\n",
            "```\n",
            "\n",
            "## Exercises\n",
            "\n",
            "1. Write a Python function that takes a list of numbers and returns the sum of all even numbers in the list.\n",
            "\n",
            "```python\n",
            "def sum_even(numbers):\n",
            "   \"\"\"\n",
            "   Returns the sum of all even numbers in the list\n",
            "   \"\"\"\n",
            "   return sum(num for num in numbers if\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer(prompt, return_tensors=\"pt\", return_attention_mask=False)\n",
        "\n",
        "outputs = model.generate(**inputs, max_length=200)\n",
        "text = tokenizer.batch_decode(outputs)[0]\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iFL5t_J-89BR"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "What is a quantum computer?\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISRBsGZv9rG4",
        "outputId": "e3ccc2e6-f3d2-4583-e676-93b0416dc1ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "What is a quantum computer?\n",
            "A quantum computer is a type of computer that uses the principles of quantum mechanics to perform calculations. Unlike classical computers, which use bits (0s and 1s) to represent information, quantum computers use quantum bits (qubits) that can exist in multiple states at the same time. This allows quantum computers to perform calculations much faster than classical computers.\n",
            "\n",
            "How does a quantum computer work?\n",
            "A quantum computer works by using the principles of quantum mechanics to perform calculations. The qubits are stored in a quantum register, which is a type of memory that can store multiple qubits at the same time. The qubits are then manipulated using quantum gates, which are operations that can change the state of the qubits.\n",
            "\n",
            "What are some applications of quantum computing?\n",
            "Quantum computing has many potential applications, including solving complex problems in chemistry, physics, and engineering. It could also be used to develop new drugs and materials, as well as to\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer(prompt, return_tensors=\"pt\", return_attention_mask=False)\n",
        "\n",
        "outputs = model.generate(**inputs, max_length=200)\n",
        "text = tokenizer.batch_decode(outputs)[0]\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8Qr97Z7z-BpU"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "2354 + 5617 =\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhydfRSw-aL_",
        "outputId": "398a07b0-abbd-44f5-b045-3062c2023354"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "2354 + 5617 =\n",
            "\n",
            "To add these two numbers, we start by adding the ones place digits: 4 + 7 = 11. Since 11 is greater than 9, we write down the 1 in the ones place and carry over the 1 to the tens place. Then, we add the tens place digits: 1 + 5 + 1 (carried over) = 9. Therefore, the sum of 2354 and 5617 is 9,921.\n",
            "\n",
            "Now, let's explore some real-world examples where addition is used.\n",
            "\n",
            "Example 1: Grocery Shopping\n",
            "Imagine you are at the grocery store with your friend. You have a shopping list with the prices of each item. To calculate the total cost of your groceries, you need to add up the prices of all the items. Let's say you have apples for $2.50, bread for $1.75, and milk for $3.25. To find the total cost, you would add\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer(prompt, return_tensors=\"pt\", return_attention_mask=False)\n",
        "\n",
        "outputs = model.generate(**inputs, max_length=200)\n",
        "text = tokenizer.batch_decode(outputs)[0]\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPNcL7aRzJY4Og0IkFfin0w",
      "gpuType": "V100",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.18 ('.venv': poetry)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.18"
    },
    "vscode": {
      "interpreter": {
        "hash": "17a011378fed683b21aba93e5dd7c0cb7beefc09c5af72c6425b40c713e260dc"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}