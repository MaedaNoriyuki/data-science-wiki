{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyP1JRA5VqArUC0mFasH5fIW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Whisper large-v3"
      ],
      "metadata": {
        "id": "_SktOlvKCVSh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Whisper Large V3は、OpenAIによって開発された先進的な自動音声認識（ASR）および音声翻訳モデルです。このモデルは、従来の80メル周波数ビンから拡張された128メル周波数ビンを使用し、音声の特徴をより詳細に捉えます。さらに、新たに広東語のサポートが追加されたことで、多言語対応能力が強化されています。Whisper Large V3は、1,000,000時間の弱ラベル付きオーディオと、4,000,000時間の擬似ラベル付きオーディオでトレーニングされ、多様な言語やアクセント、環境ノイズにも高い適応性を示しています。このモデルは、音声認識だけでなく、音声翻訳のタスクにも優れたパフォーマンスを発揮し、前モデルであるWhisper Large V2と比較して、10%から20%のエラー率の低下を達成しています。\n",
        "- HuggingFace：https://huggingface.co/openai/whisper-large-v3"
      ],
      "metadata": {
        "id": "mt8y7LTJCVOe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/fuyu-quant/data-science-wiki/blob/main/multimodal/speech_to_text/whisper_large-v3.ipynb\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "cGMcxYulCVJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install datasets\n",
        "!pip install accelerate"
      ],
      "metadata": {
        "id": "2q3pA_3FDcnE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "zR5AgmQMDj8i"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### データの用意"
      ],
      "metadata": {
        "id": "cKrY6-LeEdPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")\n",
        "sample = dataset[0][\"audio\"]"
      ],
      "metadata": {
        "id": "_UgsCp9dEcbg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Whisper large-v3の実行"
      ],
      "metadata": {
        "id": "h6TI5MPREfML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(\"openai/whisper-large-v3\", torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True).to(device)\n",
        "processor = AutoProcessor.from_pretrained(\"openai/whisper-large-v3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySl4KTwfEOLr",
        "outputId": "307743ff-9f7f-430d-db87-26d552854e08"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "aAJM8wQ8CRIF"
      },
      "outputs": [],
      "source": [
        "pipe = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=model,\n",
        "    tokenizer=processor.tokenizer,\n",
        "    feature_extractor=processor.feature_extractor,\n",
        "    max_new_tokens=128,\n",
        "    chunk_length_s=30,\n",
        "    batch_size=16,\n",
        "    return_timestamps=True,\n",
        "    torch_dtype=torch_dtype,\n",
        "    device=device,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipe(sample)\n",
        "result[\"text\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "44zmOGoJEorV",
        "outputId": "1c181c42-6d72-4dba-ae7f-38ad9b4a67de"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel. Nor is Mr. Quilter's manner less interesting than his matter. He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similes drawn from eating and its results occur most readily to the mind. He has grave doubts whether Sir Frederick Leighton's work is really Greek after all, and can discover in it but little of rocky Ithaca. Linnell's pictures are a sort of Upguards and Adam paintings, and Mason's exquisite idylls are as national as a jingo poem. Mr. Burkett Foster's landscapes smile at one much in the same way that Mr. Carker used to flash his teeth. And Mr. John Collier gives his sitter a cheerful slap on the back before he says, like a shampooer in a Turkish bath, Next man!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}