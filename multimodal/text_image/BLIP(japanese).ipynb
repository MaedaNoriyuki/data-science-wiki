{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOszOPhV-Esu"
      },
      "source": [
        "# BLIP(日本語)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* https://huggingface.co/stabilityai/japanese-instructblip-alpha"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMtuKB2_NNO6"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fuyu-quant/data-science-wiki/blob/main/multimodal/text_image/BLIP(japanese).ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "275xzg3a47Ih"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install sentencepiece einops transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vy-zyHSC_Nus"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import LlamaTokenizer, AutoModelForVision2Seq, BlipImageProcessor\n",
        "\n",
        "from PIL import Image\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnYEyJec5DW2"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForVision2Seq.from_pretrained(\"stabilityai/japanese-instructblip-alpha\", trust_remote_code=True)\n",
        "processor = BlipImageProcessor.from_pretrained(\"stabilityai/japanese-instructblip-alpha\")\n",
        "\n",
        "tokenizer = LlamaTokenizer.from_pretrained(\"novelai/nerdstash-tokenizer-v1\", additional_special_tokens=['▁▁'])\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "BGS0aij_CUJy",
        "outputId": "98676b45-9208-4192-c204-6e8c2f815db9"
      },
      "outputs": [],
      "source": [
        "url = \"https://img.peapix.com/e27fcf12e0664a5cb1c6b58c6b311d31.jpg?attachment&modal\"\n",
        "image = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\n",
        "image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "LzauL27aCOz5",
        "outputId": "3b5856c4-2ec5-4748-e925-53630c51595f"
      },
      "outputs": [],
      "source": [
        "inputs = processor(image, return_tensors=\"pt\").to(device, torch.float16)\n",
        "\n",
        "generated_ids = model.generate(**inputs, max_new_tokens=20)\n",
        "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gi0QSUqCSHA"
      },
      "outputs": [],
      "source": [
        "question = \"\"\n",
        "prompt = f\"Question: {question} Answer:\"\n",
        "\n",
        "inputs = processor(image, text = prompt, return_tensors=\"pt\").to(device, torch.float16)\n",
        "\n",
        "generated_ids = model.generate(**inputs, max_new_tokens=20)\n",
        "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jbFlwZvu9217"
      },
      "outputs": [],
      "source": [
        "# helper function to format input prompts\n",
        "def build_prompt(prompt=\"\", sep=\"\\n\\n### \"):\n",
        "    sys_msg = \"以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\"\n",
        "    p = sys_msg\n",
        "    roles = [\"指示\", \"応答\"]\n",
        "    user_query = \"与えられた画像について、詳細に述べてください。\"\n",
        "    msgs = [\": \\n\" + user_query, \": \"]\n",
        "    if prompt:\n",
        "        roles.insert(1, \"入力\")\n",
        "        msgs.insert(1, \": \\n\" + prompt)\n",
        "    for role, msg in zip(roles, msgs):\n",
        "        p += sep + role + msg\n",
        "    return p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XQvgcYc65Ob",
        "outputId": "c7ddd297-cd69-445b-9de8-af0e61137832"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "東京の夜景\n"
          ]
        }
      ],
      "source": [
        "question = \"この画像はなんですか?\"\n",
        "question = \"\"\n",
        "\n",
        "prompt = build_prompt(question)\n",
        "inputs = processor(images=image, return_tensors=\"pt\")\n",
        "text_encoding = tokenizer(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
        "text_encoding[\"qformer_input_ids\"] = text_encoding[\"input_ids\"].clone()\n",
        "text_encoding[\"qformer_attention_mask\"] = text_encoding[\"attention_mask\"].clone()\n",
        "inputs.update(text_encoding)\n",
        "\n",
        "# generate\n",
        "outputs = model.generate(\n",
        "    **inputs.to(device, dtype=model.dtype),\n",
        "    num_beams=5,\n",
        "    max_new_tokens=32,\n",
        "    min_length=1,\n",
        ")\n",
        "generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0].strip()\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzDZW5wpRZNv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMreRx/6AJJMfCaDPmuai5a",
      "gpuType": "A100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.18 ('.venv': poetry)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.18"
    },
    "vscode": {
      "interpreter": {
        "hash": "17a011378fed683b21aba93e5dd7c0cb7beefc09c5af72c6425b40c713e260dc"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
