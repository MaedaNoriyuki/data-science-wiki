{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sE1FkH0lf2HN"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "作成中"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cdn_GVVHf7S4",
        "outputId": "778b189f-6401-421b-a7dc-a097e5941147"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "#データを分割するツール\n",
        "from sklearn.model_selection import train_test_split\n",
        "#精度を評価するための混同行列とAUC(正解率)\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "#データセットMNISTのインポート\n",
        "from sklearn.datasets import fetch_openml\n",
        "#pytorch用のパッケージのインストール\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "#GPUを使う\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrYCWDUzfxAx"
      },
      "source": [
        "## データの準備\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "o0DErVWqjUDB"
      },
      "outputs": [],
      "source": [
        "x,labels = fetch_openml('mnist_784',return_X_y=True)\n",
        "#データ型がobjectなのでint型に変換\n",
        "y = labels.astype(np.int32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfBLgjh-kId6"
      },
      "source": [
        "##### Convolutional Neural Networkでは入力として多次元データを受け取る。\n",
        " 入力するデータは、(バッチサイズ、チャンネル数、画像の横幅、画像の縦幅)となる。\n",
        "#####例えば128×128のカラー画像データをバッチサイズ30で入力する場合は\n",
        "(30,3,128,128)となる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JR4CdjaplZ2L",
        "outputId": "fb4a43ba-9de6-4142-9e7e-9688aae26fed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(70000, 1, 28, 28)"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#784次元のMNISTデータを画像形式に変換する\n",
        "#もともと画像形式のデータはこの変換を行う必要はない\n",
        "#-1は、他の値を決めた時に残りの値を調整してくれる\n",
        "x = x.reshape(-1,1,28,28)\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mw_UrgrJnWRw"
      },
      "source": [
        "## モデルの作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY0Dtj7TnZ3E",
        "outputId": "5dcdd7fa-b48b-4653-88e5-080de0e99631"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU()\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=20, bias=True)\n",
            "    (1): Sigmoid()\n",
            "    (2): Linear(in_features=20, out_features=10, bias=True)\n",
            "    (3): LogSoftmax(dim=1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    #特徴量抽出器\n",
        "    #畳み込み層+活性化関数+プーリング層が2回あり\n",
        "    #kernel_sizeはフィルターの大きさ、strideはフィルターのずらし方、paddingは周りを何マス埋めるか(画像のサイズを変更しないように埋める)\n",
        "    self.features = nn.Sequential(\n",
        "        nn.Conv2d(1, 8, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2),\n",
        "\n",
        "        nn.Conv2d(8,16, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2)\n",
        "    )\n",
        "\n",
        "\n",
        "    #分類器\n",
        "    #2段階の全結合層\n",
        "    #特徴抽出器によって最終的に16個のフィルターに7×7のデータとなっているので分類器への特徴量の入力は16×49=784となる。\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Linear(784,20),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Linear(20,10),\n",
        "        nn.LogSoftmax(dim=1)\n",
        "    )\n",
        "\n",
        "    #順伝播(データが実際に入ってきた時の処理を書く)  \n",
        "  def forward(self, x):\n",
        "    h = self.features(x)\n",
        "\n",
        "    #畳み込み層の出力はまだ画像データの形になっているので、それをベクトルの形変換\n",
        "    #view関数はテンソルの形を変形する関数で引数は(行、列)、-1を代入すると他の指定した数値に合わせてくれる\n",
        "    h = h.view(len(x), -1)\n",
        "\n",
        "    return self.classifier(h)\n",
        "\n",
        "\n",
        "#ネットワークのインスタンスを作成\n",
        "net = Net()\n",
        "\n",
        "#モデルをGPUにおくる\n",
        "net = net.to(device)\n",
        "print(net)\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRmumUwo4B-M"
      },
      "source": [
        "# データの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "byaZu_Ea4Go9"
      },
      "outputs": [],
      "source": [
        "#データを学習用と評価用に分割\n",
        "split = train_test_split(x, y, train_size=0.8, test_size=0.2)\n",
        "train_features, test_features, train_labels, test_labels = split\n",
        "\n",
        "#学習用データの2割を検証用に利用\n",
        "split = train_test_split(train_features, train_labels, train_size = 0.8, test_size =0.2 )\n",
        "train_features, valid_features , train_labels, valid_labels = split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Q2vUZKW9FF9"
      },
      "source": [
        "#### num_workersはミニバッチの取り出しをCPUのコアの数だけ同時に実行する設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmbPLAUn9k_v",
        "outputId": "2616c3ed-f3a9-4053-983b-62a62a97fabc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#CPUのコアの数は以下で確認できる\n",
        "import os \n",
        "os.cpu_count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "NWhTkceZ6HhJ"
      },
      "outputs": [],
      "source": [
        "#データの準備\n",
        "\n",
        "#学習用データ\n",
        "train_features = torch.Tensor(train_features)\n",
        "train_labels = torch.LongTensor(train_labels)\n",
        "train_set = torch.utils.data.TensorDataset(train_features, train_labels)\n",
        "train_loader = torch.utils.data.DataLoader(train_set,batch_size = 100, shuffle = True, num_workers = 2)\n",
        "\n",
        "#検証用データ\n",
        "valid_features = torch.Tensor(valid_features)\n",
        "valid_labels = torch.LongTensor(valid_labels)\n",
        "valid_set = torch.utils.data.TensorDataset(valid_features, valid_labels)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_set,batch_size = 100, shuffle = True, num_workers = 2)\n",
        "\n",
        "#評価用データ\n",
        "test_features = torch.Tensor(test_features)\n",
        "test_labels = torch.LongTensor(test_labels)\n",
        "test_set = torch.utils.data.TensorDataset(test_features, test_labels)\n",
        "test_loader = torch.utils.data.DataLoader(test_set,batch_size = 4, shuffle = False, num_workers = 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djL8JNE_91QD"
      },
      "source": [
        "# 学習ステップ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "Y3kYqQ-f93nH"
      },
      "outputs": [],
      "source": [
        "#誤差関数(NLLLossはNegative Log Likelihood loss)\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "#最適化\n",
        "optimizer = optim.Adam(net.parameters(), lr = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPQCFaL9-aB1",
        "outputId": "6a89fdb3-f01b-4506-9328-ffe45b59308f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1] loss: 1.116184e-02, accuracy: 0.854, val_loss: 5.497938e-03, val_accuracy: 0.945\n",
            "[2] loss: 3.702093e-03, accuracy: 0.956, val_loss: 2.540993e-03, val_accuracy: 0.961\n",
            "[3] loss: 1.930651e-03, accuracy: 0.969, val_loss: 1.656484e-03, val_accuracy: 0.968\n",
            "[4] loss: 1.335347e-03, accuracy: 0.975, val_loss: 1.241489e-03, val_accuracy: 0.976\n",
            "[5] loss: 1.010089e-03, accuracy: 0.979, val_loss: 1.031625e-03, val_accuracy: 0.974\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "#学習のループ\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "stages = {\"train\":train_loader,\"valid\":valid_loader}\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for stage, loader in stages.items():\n",
        "    if stage == \"train\":\n",
        "      #モデルを学習モードに変更\n",
        "       net = net.train()\n",
        "    else:\n",
        "      #モデルを評価モードに変更(dropoutをoffにし、batch normを正規化のために使うようにする)\n",
        "      net = net.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for inputs, labels in loader:\n",
        "      #GPUに送る\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      #勾配を初期化\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      #順伝播\n",
        "      outputs = net(inputs)\n",
        "\n",
        "      #誤差を計算\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      if stage == \"train\":\n",
        "        #逆伝播\n",
        "        loss.backward()\n",
        "\n",
        "        #パラメータの更新\n",
        "        optimizer.step()\n",
        "        \n",
        "      #推定結果を保持\n",
        "      predicted = outputs.max(1, keepdim=True)[1]\n",
        "      total_correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
        "\n",
        "      # 誤差を記録\n",
        "      total_loss += loss.item()\n",
        "      total_samples += len(inputs)\n",
        "\n",
        "    # 1エポック分の計算結果をまとめて表示\n",
        "    total_loss /= total_samples\n",
        "    total_correct /= total_samples\n",
        "    if stage == \"train\":\n",
        "      print('[%d] loss: %e, accuracy: %.3f' % (epoch + 1, total_loss, total_correct), end=\", \")\n",
        "    else:\n",
        "      print('val_loss: %e, val_accuracy: %.3f' % (total_loss, total_correct))\n",
        "\n",
        "# 学習が終了したらモデルを保存する\n",
        "print('Finished Training')\n",
        "torch.save(net.state_dict(), \"trained.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn8Q3sHZGGKH"
      },
      "source": [
        "# テストステップ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2xUe52qFrIc",
        "outputId": "0a998b8e-dbf1-4390-f80d-afbb1ad52992"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#学習したモデルを読み込む\n",
        "\n",
        "#モデルの形(インスタンス)を読み込む\n",
        "test_net = Net()\n",
        "\n",
        "#読み込んだ形の上にパラメータを読み込む\n",
        "test_net.load_state_dict(torch.load(\"trained.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "bfHklG8SG62o"
      },
      "outputs": [],
      "source": [
        "#モデルを評価モードに変更\n",
        "\n",
        "test_net = test_net.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKaPW8_LIltx",
        "outputId": "b8ff6021-b461-4293-e80e-566687936264"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_loss: 2.777035e-02, test_accuracy: 0.972\n"
          ]
        }
      ],
      "source": [
        "# 評価のループ\n",
        "\n",
        "losses = []\n",
        "predicts = []\n",
        "gts = []\n",
        "\n",
        "for inputs, labels in test_loader:  # 学習データを1バッチ分取得\n",
        "    # GPUがあればGPUに送る\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # 順伝播(torch.no_gradは勾配の計算をしないようにしている、それによりメモリ消費を抑えられる)\n",
        "    with torch.no_grad():\n",
        "        outputs = net(inputs)\n",
        "\n",
        "    # 誤差を計算\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # 推定結果を記録\n",
        "    predicted = outputs.max(1, keepdim=True)[1]\n",
        "\n",
        "    # 誤差を記録\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    #.detach().numpy()でtensorからnumpyに変換\n",
        "    #.cpu()で、データをcpuに移せる\n",
        "    predicts.extend(predicted.cpu().detach().numpy())\n",
        "    gts.extend(labels.cpu().detach().numpy())\n",
        "\n",
        "#total_lossの値をlen(gts)(labelsの長さ)で割って代入している、つまり誤差の総和の平均を出している\n",
        "total_loss /= len(gts)\n",
        "print('test_loss: %e, test_accuracy: %.3f' % (total_loss, accuracy_score(gts, predicts)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMFVgRR/d3QXWMoBtvtvnzo",
      "include_colab_link": true,
      "name": "CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
