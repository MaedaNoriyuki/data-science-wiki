{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Proximal Policy Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jpo_FmjeCECz"
      },
      "source": [
        "* GPT-2を強化学習により精度を良くする\n",
        "* https://github.com/lvwerra/trl\n",
        "* https://github.com/lvwerra/trl/blob/main/examples/notebooks/gpt2-sentiment-ppo-training.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fuyu-quant/Data_Science/blob/main/Reinforcement_Learning/trl_GPT_2%2BPPO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NR87QGuZoVg_"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install trl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHX-ytCCsfFl",
        "outputId": "4e369bfc-83ae-4c25-ae50-933384f27c3f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import wandb\n",
        "import time\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "tqdm.pandas()\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "from transformers import AutoTokenizer, pipeline\n",
        "\n",
        "from trl.gpt2 import GPT2HeadWithValueModel, respond_to_batch\n",
        "from trl.ppo import PPOTrainer\n",
        "from trl.core import build_bert_batch_from_txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 988
        },
        "id": "8tDvxVz6uPja",
        "outputId": "4be01af1-3000-4798-8bda-738c95f77afd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:it5pmaj3) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>env/reward_mean</td><td>▁█▁▃</td></tr><tr><td>env/reward_std</td><td>▅▁█▃</td></tr><tr><td>objective/entropy</td><td>█▁▇█</td></tr><tr><td>objective/kl</td><td>▁▅▃█</td></tr><tr><td>objective/kl_coef</td><td>█▆▃▁</td></tr><tr><td>ppo/loss/policy</td><td>▁█▄▁</td></tr><tr><td>ppo/loss/total</td><td>██▄▁</td></tr><tr><td>ppo/loss/value</td><td>█▃▂▁</td></tr><tr><td>ppo/mean_non_score_reward</td><td>█▄▆▁</td></tr><tr><td>ppo/policy/advantages_mean</td><td>▄█▁▆</td></tr><tr><td>ppo/policy/approxkl</td><td>▁▇█▆</td></tr><tr><td>ppo/policy/clipfrac</td><td>▁▅▇█</td></tr><tr><td>ppo/policy/entropy</td><td>▆▁█▅</td></tr><tr><td>ppo/policy/policykl</td><td>█▁▃▃</td></tr><tr><td>ppo/returns/mean</td><td>█▅▃▁</td></tr><tr><td>ppo/returns/var</td><td>▁▂▇█</td></tr><tr><td>ppo/val/clipfrac</td><td>█▃▂▁</td></tr><tr><td>ppo/val/error</td><td>█▂▂▁</td></tr><tr><td>ppo/val/mean</td><td>█▄▃▁</td></tr><tr><td>ppo/val/var</td><td>█▃▁▁</td></tr><tr><td>ppo/val/var_explained</td><td>▁▆██</td></tr><tr><td>ppo/val/vpred</td><td>█▄▂▁</td></tr><tr><td>time/epoch</td><td>█▃▁▄</td></tr><tr><td>time/get_response</td><td>▆▁▇█</td></tr><tr><td>time/get_sentiment_preds</td><td>▁██▄</td></tr><tr><td>time/optimization</td><td>██▁▃</td></tr><tr><td>time/ppo/calc_stats</td><td>▁█▅▅</td></tr><tr><td>time/ppo/compute_rewards</td><td>▆▃▁█</td></tr><tr><td>time/ppo/forward_pass</td><td>▃▁▆█</td></tr><tr><td>time/ppo/optimize_step</td><td>██▁▃</td></tr><tr><td>time/ppo/total</td><td>██▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>env/reward_mean</td><td>0.84782</td></tr><tr><td>env/reward_std</td><td>0.13917</td></tr><tr><td>objective/entropy</td><td>48.37888</td></tr><tr><td>objective/kl</td><td>0.96516</td></tr><tr><td>objective/kl_coef</td><td>0.19694</td></tr><tr><td>ppo/loss/policy</td><td>-0.09175</td></tr><tr><td>ppo/loss/total</td><td>-0.08558</td></tr><tr><td>ppo/loss/value</td><td>0.06172</td></tr><tr><td>ppo/mean_non_score_reward</td><td>-0.19008</td></tr><tr><td>ppo/policy/advantages_mean</td><td>0.0</td></tr><tr><td>ppo/policy/approxkl</td><td>1.47927</td></tr><tr><td>ppo/policy/clipfrac</td><td>0.64012</td></tr><tr><td>ppo/policy/entropy</td><td>4.34025</td></tr><tr><td>ppo/policy/policykl</td><td>-0.20699</td></tr><tr><td>ppo/returns/mean</td><td>0.75341</td></tr><tr><td>ppo/returns/var</td><td>0.02593</td></tr><tr><td>ppo/val/clipfrac</td><td>0.19651</td></tr><tr><td>ppo/val/error</td><td>0.10642</td></tr><tr><td>ppo/val/mean</td><td>0.76808</td></tr><tr><td>ppo/val/var</td><td>0.05682</td></tr><tr><td>ppo/val/var_explained</td><td>-3.10334</td></tr><tr><td>ppo/val/vpred</td><td>0.75358</td></tr><tr><td>time/epoch</td><td>128.87652</td></tr><tr><td>time/get_response</td><td>56.55909</td></tr><tr><td>time/get_sentiment_preds</td><td>0.1888</td></tr><tr><td>time/optimization</td><td>72.12151</td></tr><tr><td>time/ppo/calc_stats</td><td>0.29496</td></tr><tr><td>time/ppo/compute_rewards</td><td>0.09476</td></tr><tr><td>time/ppo/forward_pass</td><td>0.90974</td></tr><tr><td>time/ppo/optimize_step</td><td>70.42428</td></tr><tr><td>time/ppo/total</td><td>71.72418</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">run-42</strong> at: <a href=\"https://wandb.ai/toma_tanaka/gpt2-test/runs/it5pmaj3\" target=\"_blank\">https://wandb.ai/toma_tanaka/gpt2-test/runs/it5pmaj3</a><br/>Synced 5 W&B file(s), 4 media file(s), 4 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230116_141458-it5pmaj3/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:it5pmaj3). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230116_144446-n8twjthb</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/toma_tanaka/gpt2-test/runs/n8twjthb\" target=\"_blank\">run-42</a></strong> to <a href=\"https://wandb.ai/toma_tanaka/gpt2-test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href=\"https://wandb.ai/toma_tanaka/gpt2-test\" target=\"_blank\">https://wandb.ai/toma_tanaka/gpt2-test</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href=\"https://wandb.ai/toma_tanaka/gpt2-test/runs/n8twjthb\" target=\"_blank\">https://wandb.ai/toma_tanaka/gpt2-test/runs/n8twjthb</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/toma_tanaka/gpt2-test/runs/n8twjthb?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f0601ff34f0>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config = {\n",
        "    \"model_name\": \"lvwerra/gpt2-imdb\",\n",
        "    \"cls_model_name\": \"lvwerra/distilbert-imdb\",\n",
        "    \"steps\": 10000,\n",
        "    \"batch_size\": 256,\n",
        "    \"forward_batch_size\": 16,\n",
        "    \"ppo_epochs\": 4,   \n",
        "    \"txt_in_min_len\": 2,\n",
        "    \"txt_in_max_len\": 8,\n",
        "    \"txt_out_min_len\": 4,\n",
        "    \"txt_out_max_len\": 16,\n",
        "    \"lr\": 1.41e-5,\n",
        "    \"init_kl_coef\":0.2,\n",
        "    \"target\": 6,\n",
        "    \"horizon\":10000,\n",
        "    \"gamma\":1,\n",
        "    \"lam\":0.95,\n",
        "    \"cliprange\": .2,\n",
        "    \"cliprange_value\":.2,\n",
        "    \"vf_coef\":.1, \n",
        "}\n",
        "\n",
        "# deviceの設定\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "pipe_device = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "\n",
        "wandb.init(name='run-42', project='gpt2-test', config=config, )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gy7zdfE6kew"
      },
      "source": [
        "## データの準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2VwtFrOuUch",
        "outputId": "37c6c639-da3e-4713-cb76-62bde25b3aa3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Found cached dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-026fd5faee8a87db.arrow\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['review', 'sentiment'],\n",
              "    num_rows: 24895\n",
              "})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds = load_dataset('imdb', split='train')\n",
        "ds = ds.rename_columns({'text': 'review', 'label': 'sentiment'})\n",
        "ds = ds.filter(lambda x: len(x[\"review\"])>200, batched=False)\n",
        "ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v81ztOo-6ooT"
      },
      "source": [
        "## 感情分類モデルのBERTの用意"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "E6NNzv-7uoNt"
      },
      "outputs": [],
      "source": [
        "sent_kwargs = {\n",
        "    \"return_all_scores\": True,\n",
        "    \"function_to_apply\": \"none\",\n",
        "    \"batch_size\": config[\"forward_batch_size\"]\n",
        "}\n",
        "\n",
        "sentiment_pipe = pipeline(\"sentiment-analysis\",\"lvwerra/distilbert-imdb\", device=pipe_device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE7l2ghp2sgs"
      },
      "source": [
        "## GPT2モデルのロード"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NazTXaqZuyAi",
        "outputId": "1c0a5a12-0221-41fd-c853-d61682b1a02c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of GPT2HeadWithValueModel were not initialized from the model checkpoint at lvwerra/gpt2-imdb and are newly initialized: ['transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.11.attn.masked_bias', 'v_head.summary.weight', 'v_head.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of GPT2HeadWithValueModel were not initialized from the model checkpoint at lvwerra/gpt2-imdb and are newly initialized: ['transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.11.attn.masked_bias', 'v_head.summary.weight', 'v_head.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# 一つ目のモデルは強化学習により最適化される\n",
        "gpt2_model = GPT2HeadWithValueModel.from_pretrained(config['model_name'])\n",
        "# 二つ目のモデルはKL-divergenceを計算するために参照される\n",
        "# 最適化されるモデルがPPO学習により、元のモデルと大きく変わってしまわないようにするための報酬として使う\n",
        "gpt2_model_ref = GPT2HeadWithValueModel.from_pretrained(config['model_name'])\n",
        "\n",
        "gpt2_model.to(device);\n",
        "gpt2_model_ref.to(device);\n",
        "\n",
        "\n",
        "gpt2_tokenizer = AutoTokenizer.from_pretrained(config['model_name'])\n",
        "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6x_VwEIuzzW",
        "outputId": "49d62a4b-0218-48d5-d879-357b17719f0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.watch(gpt2_model, log='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RaP7jrb32I4"
      },
      "source": [
        "## レビューのトークン化\n",
        "* クエリとレスポンスの長さをランダムにしたいのである区間から値をサンプリングする"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fI5IleZru4As"
      },
      "outputs": [],
      "source": [
        "class LengthSampler:\n",
        "    def __init__(self, min_value, max_value):\n",
        "        self.values = list(range(min_value, max_value))\n",
        "    def __call__(self):\n",
        "        return np.random.choice(self.values)\n",
        "    \n",
        "input_size = LengthSampler(config[\"txt_in_min_len\"], config[\"txt_in_max_len\"])\n",
        "output_size = LengthSampler(config[\"txt_out_min_len\"], config[\"txt_out_max_len\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35VFciUh4aY5"
      },
      "source": [
        "トークン化の重複を避けるため、あらかじめすべてのIMDBをトークン化する。最初のステップでは、クエリーをエンコードし、最初の input_size() トークンをスライスします。第二段階では、これらのトークンをデコードしてテキストに戻し、後で表示する。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReH9ifgyu4xZ",
        "outputId": "52b4e7a3-c09e-4e1c-95f4-456773f220bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-e01d72af337f58df.arrow\n"
          ]
        }
      ],
      "source": [
        "def tokenize(sample):\n",
        "    sample[\"tokens\"] = gpt2_tokenizer.encode(sample[\"review\"])[:input_size()]\n",
        "    sample[\"query\"] = gpt2_tokenizer.decode(sample[\"tokens\"])\n",
        "    return sample\n",
        "\n",
        "ds = ds.map(tokenize, batched=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tpmvpSR5u6tX"
      },
      "outputs": [],
      "source": [
        "# 生成時のサンプリングの設定\n",
        "gen_kwargs = {\n",
        "    \"min_length\":-1,\n",
        "    \"top_k\": 0.0,\n",
        "    \"top_p\": 1.0,\n",
        "    \"do_sample\": True,\n",
        "    \"pad_token_id\": gpt2_tokenizer.eos_token_id\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2i_qx4h6u8ZZ"
      },
      "outputs": [],
      "source": [
        "def collater(data):\n",
        "    return dict((key, [d[key] for d in data]) for key in data[0])\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(ds, batch_size=config['batch_size'], collate_fn=collater)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpuV2AH3vCf9"
      },
      "source": [
        "## 学習"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDP6J7dMu-dn",
        "outputId": "a144116c-18d0-4f7b-9f08-229cc12f2191"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "4it [08:35, 128.99s/it]\n"
          ]
        }
      ],
      "source": [
        "ppo_trainer = PPOTrainer(gpt2_model, gpt2_model_ref, gpt2_tokenizer, **config)\n",
        "\n",
        "total_ppo_epochs = int(np.ceil(config[\"steps\"]/config['batch_size']))\n",
        "\n",
        "for epoch, batch in tqdm(zip(range(total_ppo_epochs), iter(dataloader))):\n",
        "    logs, timing = dict(), dict()\n",
        "    t0 = time.time()\n",
        "    query_tensors = [torch.tensor(t).long().to(device) for t in batch[\"tokens\"]]\n",
        "    \n",
        "    # GPT-2による出力\n",
        "    t = time.time()\n",
        "    response_tensors = []\n",
        "    for i in range(config['batch_size']):\n",
        "        gen_len = output_size()\n",
        "        response = gpt2_model.generate(query_tensors[i].unsqueeze(dim=0),\n",
        "                                       max_new_tokens=gen_len, **gen_kwargs)\n",
        "        response_tensors.append(response.squeeze()[-gen_len:])\n",
        "    batch['response'] = [gpt2_tokenizer.decode(r.squeeze()) for r in response_tensors]\n",
        "    timing['time/get_response'] = time.time()-t\n",
        "\n",
        "\n",
        "\n",
        "    # BERTによる感情の出力\n",
        "    t = time.time()\n",
        "    texts = [q + r for q,r in zip(batch['query'], batch['response'])]\n",
        "    pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n",
        "    #print(pipe_outputs)\n",
        "    #rewards = torch.tensor([output[1][\"score\"] for output in pipe_outputs]).to(device)\n",
        "    rewards = torch.tensor([output[\"score\"] for output in pipe_outputs]).to(device)\n",
        "    timing['time/get_sentiment_preds'] = time.time()-t\n",
        "    \n",
        "\n",
        "\n",
        "    # PPOによるポリシーの最適化\n",
        "    t = time.time()\n",
        "    stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n",
        "    timing['time/optimization'] = time.time()-t\n",
        "     \n",
        "\n",
        "\n",
        "    #### Log everything\n",
        "    timing['time/epoch'] = time.time()-t0\n",
        "    table_rows = [list(r) for r in zip(batch['query'], batch['response'], rewards.cpu().tolist())]\n",
        "    logs.update({'game_log': wandb.Table(columns=['query', 'response', 'reward'], rows=table_rows)})\n",
        "    logs.update(timing)\n",
        "    logs.update(stats)\n",
        "    logs['env/reward_mean'] = torch.mean(rewards).cpu().numpy()\n",
        "    logs['env/reward_std'] = torch.std(rewards).cpu().numpy()\n",
        "    logs['env/reward_dist'] = rewards.cpu().numpy()\n",
        "    wandb.log(logs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x76qR_svHKA"
      },
      "source": [
        "## 検証"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "id": "KAHN_ofvvAY8",
        "outputId": "ad30e739-a5ae-4461-f4af-7532c6014dba"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-25d20370-3bb6-4dc4-abd4-b3abd781d991\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>response (before)</th>\n",
              "      <th>response (after)</th>\n",
              "      <th>rewards (before)</th>\n",
              "      <th>rewards (after)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>After seeing the low</td>\n",
              "      <td>was looking for a way to redeem myself on my own</td>\n",
              "      <td>'t fully be referred to as \"by\" ESPN.</td>\n",
              "      <td>0.569658</td>\n",
              "      <td>0.898822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>David Duchov</td>\n",
              "      <td>, Whos Sherox</td>\n",
              "      <td>obvious and untilted approach</td>\n",
              "      <td>0.642662</td>\n",
              "      <td>0.900879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Internet</td>\n",
              "      <td>to shift it to your best external viewing. Th...</td>\n",
              "      <td>James and Richard meet up with the wild-eyed ...</td>\n",
              "      <td>0.978636</td>\n",
              "      <td>0.753606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>well, i</td>\n",
              "      <td>movie could have been about ridiculous garbag...</td>\n",
              "      <td>like a good person, so i find that he really has</td>\n",
              "      <td>0.985395</td>\n",
              "      <td>0.980146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pearl S.Buck was</td>\n",
              "      <td>his sanity a bit to</td>\n",
              "      <td>illing; it was more</td>\n",
              "      <td>0.867682</td>\n",
              "      <td>0.500588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>This is a lot of</td>\n",
              "      <td>hear,\" Cardellini said. If you enjoy mysterie...</td>\n",
              "      <td>social commentary,\" said Honor. While this po...</td>\n",
              "      <td>0.974677</td>\n",
              "      <td>0.717126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Final Score: 0 (</td>\n",
              "      <td>&gt;&lt;br /&gt;My vote: 4&lt;|endoftext|&gt;</td>\n",
              "      <td>to me as being more confident about this</td>\n",
              "      <td>0.671172</td>\n",
              "      <td>0.627530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The surprise nominee of this</td>\n",
              "      <td>Is Someone You Miss in Town ) who</td>\n",
              "      <td>courtroom drama is this is actually the latest</td>\n",
              "      <td>0.913158</td>\n",
              "      <td>0.961582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Inappropriate. The PG rating</td>\n",
              "      <td>during the scenes while</td>\n",
              "      <td>so this is a</td>\n",
              "      <td>0.972703</td>\n",
              "      <td>0.977995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>This movie deserved</td>\n",
              "      <td>This script has established</td>\n",
              "      <td>initial mild success.</td>\n",
              "      <td>0.821585</td>\n",
              "      <td>0.670530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>\"Memoirs of a Ge</td>\n",
              "      <td>zzby\", Sylvia Plath's rare filmgoing experienc...</td>\n",
              "      <td>ing Treliving Service\" distracts you from the ...</td>\n",
              "      <td>0.974832</td>\n",
              "      <td>0.766279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>It has been some years</td>\n",
              "      <td>entirely due to its</td>\n",
              "      <td>much. Most people</td>\n",
              "      <td>0.708269</td>\n",
              "      <td>0.770902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>For real film people, this</td>\n",
              "      <td>lot of scenes from bad acting, bad scenery an...</td>\n",
              "      <td>awful lot going for it. Its not for everyone,</td>\n",
              "      <td>0.994479</td>\n",
              "      <td>0.987885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>This film is to the F</td>\n",
              "      <td>persistently tries to control because of</td>\n",
              "      <td>that has given the story of the</td>\n",
              "      <td>0.935381</td>\n",
              "      <td>0.970661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>I am a</td>\n",
              "      <td>completely disgusted by this movie. The actin...</td>\n",
              "      <td>heterosexual / w/ accommodating u/friend, thi...</td>\n",
              "      <td>0.993515</td>\n",
              "      <td>0.978047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>The plot was</td>\n",
              "      <td>ying. There was absolutely no chemistry betwee...</td>\n",
              "      <td>but could have worked. Maybe Anchorman just m...</td>\n",
              "      <td>0.994462</td>\n",
              "      <td>0.976462</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25d20370-3bb6-4dc4-abd4-b3abd781d991')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-25d20370-3bb6-4dc4-abd4-b3abd781d991 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-25d20370-3bb6-4dc4-abd4-b3abd781d991');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                           query  \\\n",
              "0           After seeing the low   \n",
              "1                   David Duchov   \n",
              "2                   The Internet   \n",
              "3                        well, i   \n",
              "4               Pearl S.Buck was   \n",
              "5               This is a lot of   \n",
              "6               Final Score: 0 (   \n",
              "7   The surprise nominee of this   \n",
              "8   Inappropriate. The PG rating   \n",
              "9            This movie deserved   \n",
              "10              \"Memoirs of a Ge   \n",
              "11        It has been some years   \n",
              "12    For real film people, this   \n",
              "13         This film is to the F   \n",
              "14                        I am a   \n",
              "15                  The plot was   \n",
              "\n",
              "                                    response (before)  \\\n",
              "0    was looking for a way to redeem myself on my own   \n",
              "1                                       , Whos Sherox   \n",
              "2    to shift it to your best external viewing. Th...   \n",
              "3    movie could have been about ridiculous garbag...   \n",
              "4                                 his sanity a bit to   \n",
              "5    hear,\" Cardellini said. If you enjoy mysterie...   \n",
              "6                      ><br />My vote: 4<|endoftext|>   \n",
              "7                   Is Someone You Miss in Town ) who   \n",
              "8                             during the scenes while   \n",
              "9                         This script has established   \n",
              "10  zzby\", Sylvia Plath's rare filmgoing experienc...   \n",
              "11                                entirely due to its   \n",
              "12   lot of scenes from bad acting, bad scenery an...   \n",
              "13           persistently tries to control because of   \n",
              "14   completely disgusted by this movie. The actin...   \n",
              "15  ying. There was absolutely no chemistry betwee...   \n",
              "\n",
              "                                     response (after)  rewards (before)  \\\n",
              "0               't fully be referred to as \"by\" ESPN.          0.569658   \n",
              "1                       obvious and untilted approach          0.642662   \n",
              "2    James and Richard meet up with the wild-eyed ...          0.978636   \n",
              "3    like a good person, so i find that he really has          0.985395   \n",
              "4                                 illing; it was more          0.867682   \n",
              "5    social commentary,\" said Honor. While this po...          0.974677   \n",
              "6            to me as being more confident about this          0.671172   \n",
              "7      courtroom drama is this is actually the latest          0.913158   \n",
              "8                                        so this is a          0.972703   \n",
              "9                               initial mild success.          0.821585   \n",
              "10  ing Treliving Service\" distracts you from the ...          0.974832   \n",
              "11                                  much. Most people          0.708269   \n",
              "12      awful lot going for it. Its not for everyone,          0.994479   \n",
              "13                    that has given the story of the          0.935381   \n",
              "14   heterosexual / w/ accommodating u/friend, thi...          0.993515   \n",
              "15   but could have worked. Maybe Anchorman just m...          0.994462   \n",
              "\n",
              "    rewards (after)  \n",
              "0          0.898822  \n",
              "1          0.900879  \n",
              "2          0.753606  \n",
              "3          0.980146  \n",
              "4          0.500588  \n",
              "5          0.717126  \n",
              "6          0.627530  \n",
              "7          0.961582  \n",
              "8          0.977995  \n",
              "9          0.670530  \n",
              "10         0.766279  \n",
              "11         0.770902  \n",
              "12         0.987885  \n",
              "13         0.970661  \n",
              "14         0.978047  \n",
              "15         0.976462  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#### get a batch from the dataset\n",
        "bs = 16\n",
        "game_data = dict()\n",
        "ds.set_format(\"pandas\")\n",
        "df_batch = ds[:].sample(bs)\n",
        "game_data['query'] = df_batch['query'].tolist()\n",
        "query_tensors = df_batch['tokens'].tolist()\n",
        "\n",
        "response_tensors_ref, response_tensors = [], []\n",
        "\n",
        "#### get response from gpt2 and gpt2_ref\n",
        "for i in range(bs):\n",
        "    gen_len = output_size()\n",
        "    output = gpt2_model_ref.generate(torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(device),\n",
        "                                     max_new_tokens=gen_len, **gen_kwargs).squeeze()[-gen_len:]\n",
        "    response_tensors_ref.append(output)\n",
        "    output = gpt2_model.generate(torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(device),\n",
        "                                 max_new_tokens=gen_len, **gen_kwargs).squeeze()[-gen_len:]\n",
        "    response_tensors.append(output)\n",
        "\n",
        "#### decode responses\n",
        "game_data['response (before)'] = [gpt2_tokenizer.decode(response_tensors_ref[i]) for i in range(bs)]\n",
        "game_data['response (after)'] = [gpt2_tokenizer.decode(response_tensors[i]) for i in range(bs)]\n",
        "\n",
        "#### sentiment analysis of query/response pairs before/after\n",
        "texts = [q + r for q,r in zip(game_data['query'], game_data['response (before)'])]\n",
        "game_data['rewards (before)'] = [output[\"score\"] for output in sentiment_pipe(texts, **sent_kwargs)]\n",
        "\n",
        "texts = [q + r for q,r in zip(game_data['query'], game_data['response (after)'])]\n",
        "game_data['rewards (after)'] = [output[\"score\"] for output in sentiment_pipe(texts, **sent_kwargs)]\n",
        "\n",
        "# store results in a dataframe\n",
        "df_results = pd.DataFrame(game_data)\n",
        "df_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "jqwZn6akvPg1",
        "outputId": "e9bf9b9e-c805-40da-e1dd-a2b1b4fd04db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "rewards (before)    0.874892\n",
              "rewards (after)     0.839940\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "median:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "rewards (before)    0.954042\n",
              "rewards (after)     0.899851\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print('mean:')\n",
        "display(df_results[[\"rewards (before)\", \"rewards (after)\"]].mean())\n",
        "print()\n",
        "print('median:')\n",
        "display(df_results[[\"rewards (before)\", \"rewards (after)\"]].median())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyO3Xz57OI2Qj2a/HlLaDVMD",
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
